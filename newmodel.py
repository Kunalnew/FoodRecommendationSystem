# -*- coding: utf-8 -*-
"""NewModel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1voTQguZ_-xOVbs_y2tLYg5TW4fNTuTy5
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib
import seaborn as sns
import numpy as np
from scipy.stats import shapiro
# %matplotlib inline

df=pd.read_csv(r"D:\projects\vt\static\ObesityDataSet_raw_and_data_sinthetic.csv")

df

print(df.shape)

df[df.isnull().any(axis=1)]

"""# For missing values"""

df.isnull().sum()

df.info()

numerical_columns=df.columns[df.dtypes!='object']
categorical_columns=df.columns[df.dtypes=='object']

print("numerical_columns:",numerical_columns)
print("categorical_columns:",categorical_columns)

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(8,6))
x=0
for i in numerical_columns:
    sns.histplot(data=df,x=i,kde=True)
    print('\n')
    plt.show()

plt.figure(figsize=(8,6))
for i in categorical_columns:
    sns.catplot(data=df,x=i,kind='count')
    print('\n')
    plt.show()

sns.heatmap(df[numerical_columns].corr(),annot=True)

df.head()

for i in categorical_columns:
  print(i)

for i in categorical_columns:
  print(df[i].value_counts())
  print()
  print('---------------------')
  print()

for i in numerical_columns:
  print(df[i].value_counts())
  print()
  print('---------------------')
  print()

df

X=df.drop(['NObeyesdad'],axis=1)
Y=df[['NObeyesdad']]

X

Y

NObeyesdad_cat=['Obesity_Type_I','Obesity_Type_III','Obesity_Type_II','Overweight_Level_I','Overweight_Level_II','Normal_Weight','Insufficient_Weight']

# Segregating numerical and categorical variables
categorical_cols = X.select_dtypes(include='object').columns
numerical_cols = X.select_dtypes(exclude='object').columns

categorical_cols

numerical_cols

Gender_cat=['Male','Female']
family_history_with_overweight_cat=['yes','no']
FAVC_cat=['yes','no']
CAEC_cat=[ 'Sometimes','no','Frequently','Always']
SMOKE_cat=['yes','no']
SCC_cat=['yes','no']
CALC_cat=[ 'Sometimes','no','Frequently','Always']
MTRANS_cat=['Public_Transportation','Automobile','Walking','Motorbike','Bike']
NObeyesdad_cat=['Obesity_Type_I','Obesity_Type_III','Obesity_Type_II','Overweight_Level_I','Overweight_Level_II','Normal_Weight','Insufficient_Weight']

from sklearn.impute import SimpleImputer ## HAndling Missing Values
from sklearn.preprocessing import StandardScaler # HAndling Feature Scaling
from sklearn.preprocessing import OrdinalEncoder # Ordinal Encoding
## pipelines
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split

w = [{
    "Gender": 'Female',
    "Age": 21,
    "Height":1.62,
    "Weight":50,
    "family_history_with_overweight":'yes',
    "FAVC": 'no',
    "FCVC": 2.0,
    "NCP": 3.0,
    "CAEC": 'Sometimes',
    "SMOKE": 'no',
    "CH2O": 2.0,
    "SCC": 'no',
    "FAF": 0.0,
    "TUE": 1.0,
    "CALC": 'Sometimes',  # Corrected value
    "MTRANS": 'Public_Transportation'
}]

f=pd.DataFrame(w)

f

def Transform_data(fr,df):

  X=df.drop(['NObeyesdad'],axis=1)
  Y=df[['NObeyesdad']]

  numerical_cols=['Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE']
  categorical_cols=['Gender', 'family_history_with_overweight', 'FAVC', 'CAEC', 'SMOKE','SCC', 'CALC', 'MTRANS']



  Gender_cat=['Male','Female']
  family_history_with_overweight_cat=['yes','no']
  FAVC_cat=['yes','no']
  CAEC_cat=[ 'Sometimes','no','Frequently','Always']
  SMOKE_cat=['yes','no']
  SCC_cat=['yes','no']
  CALC_cat=[ 'Sometimes','no','Frequently','Always']
  MTRANS_cat=['Public_Transportation','Automobile','Walking','Motorbike','Bike']




  ## Numerical Pipeline
  num_pipeline=Pipeline(
      steps=[
     ('imputer',SimpleImputer(strategy='median')),
     ('scaler',StandardScaler())

     ]

  )

# Categorigal Pipeline
  cat_pipeline=Pipeline(
      steps=[
      ('imputer',SimpleImputer(strategy='most_frequent')),
      ('ordinalencoder',OrdinalEncoder(categories=[Gender_cat,family_history_with_overweight_cat,FAVC_cat,CAEC_cat,SMOKE_cat,SCC_cat,CALC_cat,MTRANS_cat])),
      ('scaler',StandardScaler())
      ]

  )

  preprocessor=ColumnTransformer([
  ('num_pipeline',num_pipeline,numerical_cols),
  ('cat_pipeline',cat_pipeline,categorical_cols)
  ])



  X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.30,random_state=30)
  X_train=pd.DataFrame(preprocessor.fit_transform(X_train),columns=preprocessor.get_feature_names_out())
  X_test=pd.DataFrame(preprocessor.transform(X_test),columns=preprocessor.get_feature_names_out())


  c = pd.DataFrame(preprocessor.transform(fr), columns=preprocessor.get_feature_names_out())

  return pd.DataFrame(c)

print(Transform_data(f,df))

"""# Mode Training"""

## Numerical Pipeline
num_pipeline=Pipeline(
    steps=[
    ('imputer',SimpleImputer(strategy='median')),
    ('scaler',StandardScaler())

    ]

)

# Categorigal Pipeline
cat_pipeline=Pipeline(
    steps=[
    ('imputer',SimpleImputer(strategy='most_frequent')),
    ('ordinalencoder',OrdinalEncoder(categories=[Gender_cat,family_history_with_overweight_cat,FAVC_cat,CAEC_cat,SMOKE_cat,SCC_cat,CALC_cat,MTRANS_cat])),
    ('scaler',StandardScaler())
    ]

)

preprocessor=ColumnTransformer([
('num_pipeline',num_pipeline,numerical_cols),
('cat_pipeline',cat_pipeline,categorical_cols)
])

from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
from sklearn.preprocessing import StandardScaler, MinMaxScaler
import pandas as pd

## Train test split
from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.30,random_state=30)

X_train=pd.DataFrame(preprocessor.fit_transform(X_train),columns=preprocessor.get_feature_names_out())
X_test=pd.DataFrame(preprocessor.transform(X_test),columns=preprocessor.get_feature_names_out())

clk=RandomForestClassifier(random_state=2020)

clk.fit(X_train,y_train)

y_predict=clk.predict(X_test)

y_predict

X_train.head(5)

clk.score(X_test,y_test)

print('Random Forest'+' : ')
print("Classification Repot\n",metrics.classification_report(y_test, y_predict))
print("-------------------")

import pickle

with open("new_classification_model.pkl",'wb') as f:
  pickle.dump(clk,f)



